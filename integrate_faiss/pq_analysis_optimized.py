#!/usr/bin/env python3
"""
PQé‡åŒ–å‚æ•°Må½±å“åˆ†æ - ä¼˜åŒ–ç‰ˆæœ¬

é’ˆå¯¹å®é™…å¯è¡Œçš„å‚æ•°èŒƒå›´è¿›è¡Œæµ‹è¯•
"""

import numpy as np
import faiss
import time
import matplotlib.pyplot as plt
import pandas as pd
from typing import List, Dict
import warnings
warnings.filterwarnings('ignore')

def pq_parameter_demo():
    """
    PQå‚æ•°Må½±å“æ¼”ç¤º
    """
    print("ğŸš€ PQé‡åŒ–å‚æ•°Må½±å“åˆ†æDemo")
    print("=" * 60)
    
    # é…ç½®å‚æ•°
    dim = 128
    nb = 20000  # å‡å°‘æ•°æ®é‡ï¼Œé¿å…è®­ç»ƒæ—¶é—´è¿‡é•¿
    nq = 500
    k = 10
    nbits = 4  # ä½¿ç”¨4ä½ï¼Œæ¯ä¸ªå­é‡åŒ–å™¨16ä¸ªèšç±»ä¸­å¿ƒ
    
    print(f"é…ç½®: dim={dim}, nb={nb}, nq={nq}, k={k}, nbits={nbits}")
    print(f"æ¯ä¸ªå­é‡åŒ–å™¨èšç±»ä¸­å¿ƒæ•°: {2**nbits}")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    database = np.random.randn(nb, dim).astype(np.float32)
    queries = np.random.randn(nq, dim).astype(np.float32)
    
    # è§„èŒƒåŒ–
    faiss.normalize_L2(database)
    faiss.normalize_L2(queries)
    
    # è®¡ç®—çœŸå®æœ€è¿‘é‚»
    print("è®¡ç®—çœŸå®æœ€è¿‘é‚»...")
    index_flat = faiss.IndexFlatL2(dim)
    index_flat.add(database)
    _, ground_truth = index_flat.search(queries, k)
    
    # æµ‹è¯•ä¸åŒMå€¼
    m_values = [4, 8, 16, 32, 64]  # é€‰æ‹©åˆç†çš„Må€¼èŒƒå›´
    results = []
    
    print(f"\nå¼€å§‹æµ‹è¯•Må€¼: {m_values}")
    print("-" * 60)
    
    for m in m_values:
        if dim % m != 0:
            print(f"è·³è¿‡ M={m}: ç»´åº¦{dim}ä¸èƒ½è¢«Mæ•´é™¤")
            continue
            
        print(f"\nğŸ”¬ æµ‹è¯• M={m} (å­å‘é‡ç»´åº¦: {dim//m})")
        
        try:
            # 1. æµ‹è¯•çº¯PQç´¢å¼•
            print("  æµ‹è¯• IndexPQ...")
            pq_result = test_pq_index(database, queries, ground_truth, dim, m, nbits, k)
            
            # 2. æµ‹è¯•HNSW+PQç´¢å¼•  
            print("  æµ‹è¯• IndexHNSWPQ...")
            hnswpq_result = test_hnswpq_index(database, queries, ground_truth, dim, m, nbits, k)
            
            # åˆå¹¶ç»“æœ
            result = {
                'M': m,
                'sub_dim': dim // m,
                'clusters_per_subvector': 2**nbits,
                **pq_result,
                **{f'hnsw_{k}': v for k, v in hnswpq_result.items()}
            }
            
            results.append(result)
            
            # æ‰“å°ç»“æœ
            print(f"    PQ: æ„å»º={pq_result['build_time']:.2f}s, "
                  f"æœç´¢={pq_result['search_time_ms']:.2f}ms, "
                  f"å¬å›ç‡@10={pq_result['recall_10']:.3f}")
            print(f"    HNSW+PQ: æ„å»º={hnswpq_result['build_time']:.2f}s, "
                  f"æœç´¢={hnswpq_result['search_time_ms']:.2f}ms, "
                  f"å¬å›ç‡@10={hnswpq_result['recall_10']:.3f}")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•M={m}å¤±è´¥: {e}")
            continue
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
        return
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)
    
    # ç»˜åˆ¶ç»“æœ
    plot_pq_results(df)
    
    # ä¿å­˜ç»“æœ
    df.to_csv('pq_analysis_results.csv', index=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: pq_analysis_results.csv")
    
    # åˆ†ææ€»ç»“
    print_analysis(df)
    
    return df

def test_pq_index(database, queries, ground_truth, dim, m, nbits, k):
    """æµ‹è¯•çº¯PQç´¢å¼•"""
    index = faiss.IndexPQ(dim, m, nbits, faiss.METRIC_L2)
    
    # è®­ç»ƒ
    start = time.time()
    index.train(database)
    index.add(database)
    build_time = time.time() - start
    
    # æœç´¢
    start = time.time()
    distances, labels = index.search(queries, k)
    search_time = (time.time() - start) * 1000 / len(queries)  # ms per query
    
    # è®¡ç®—å¬å›ç‡
    recall_1 = compute_recall(labels[:, :1], ground_truth[:, :1])
    recall_5 = compute_recall(labels[:, :5], ground_truth[:, :5])
    recall_10 = compute_recall(labels[:, :k], ground_truth[:, :k])
    
    # å†…å­˜ä¼°ç®—
    memory_mb = len(database) * m * nbits / 8 / (1024 * 1024)
    compression_ratio = (len(database) * dim * 4) / (len(database) * m * nbits / 8)
    
    return {
        'build_time': build_time,
        'search_time_ms': search_time,
        'recall_1': recall_1,
        'recall_5': recall_5,
        'recall_10': recall_10,
        'memory_mb': memory_mb,
        'compression_ratio': compression_ratio
    }

def test_hnswpq_index(database, queries, ground_truth, dim, m, nbits, k, hnsw_m=16):
    """æµ‹è¯•HNSW+PQç´¢å¼•"""
    index = faiss.IndexHNSWPQ(dim, m, nbits, hnsw_m, faiss.METRIC_L2)
    index.hnsw.efConstruction = 100  # é™ä½æ„å»ºå‚æ•°åŠ å¿«é€Ÿåº¦
    
    # è®­ç»ƒå’Œæ„å»º
    start = time.time()
    index.train(database)
    index.add(database)
    build_time = time.time() - start
    
    # æœç´¢æµ‹è¯•
    index.hnsw.efSearch = 32
    start = time.time()
    distances, labels = index.search(queries, k)
    search_time = (time.time() - start) * 1000 / len(queries)  # ms per query
    
    # è®¡ç®—å¬å›ç‡
    recall_1 = compute_recall(labels[:, :1], ground_truth[:, :1])
    recall_5 = compute_recall(labels[:, :5], ground_truth[:, :5])
    recall_10 = compute_recall(labels[:, :k], ground_truth[:, :k])
    
    # å†…å­˜ä¼°ç®—
    pq_memory = len(database) * m * nbits / 8
    hnsw_memory = len(database) * hnsw_m * 8  # è¿‘ä¼¼
    total_memory_mb = (pq_memory + hnsw_memory) / (1024 * 1024)
    
    return {
        'build_time': build_time,
        'search_time_ms': search_time,
        'recall_1': recall_1,
        'recall_5': recall_5,
        'recall_10': recall_10,
        'memory_mb': total_memory_mb
    }

def compute_recall(pred_labels, true_labels):
    """è®¡ç®—å¬å›ç‡"""
    nq, k = pred_labels.shape
    recall_sum = 0.0
    
    for i in range(nq):
        true_set = set(true_labels[i])
        pred_set = set(pred_labels[i])
        if len(true_set) > 0:
            recall_sum += len(true_set.intersection(pred_set)) / len(true_set)
    
    return recall_sum / nq

def plot_pq_results(df):
    """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.family'] = ['DejaVu Sans']
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('PQ Parameter M Impact Analysis', fontsize=14, fontweight='bold')
    
    # 1. æ„å»ºæ—¶é—´
    axes[0, 0].plot(df['M'], df['build_time'], 'o-', label='PQ', linewidth=2, markersize=6)
    axes[0, 0].plot(df['M'], df['hnsw_build_time'], 's-', label='HNSW+PQ', linewidth=2, markersize=6)
    axes[0, 0].set_xlabel('M (Number of Subquantizers)')
    axes[0, 0].set_ylabel('Build Time (seconds)')
    axes[0, 0].set_title('Index Build Time')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æœç´¢æ—¶é—´
    axes[0, 1].plot(df['M'], df['search_time_ms'], 'o-', label='PQ', linewidth=2, markersize=6)
    axes[0, 1].plot(df['M'], df['hnsw_search_time_ms'], 's-', label='HNSW+PQ', linewidth=2, markersize=6)
    axes[0, 1].set_xlabel('M (Number of Subquantizers)')
    axes[0, 1].set_ylabel('Search Time (ms/query)')
    axes[0, 1].set_title('Search Time')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. å¬å›ç‡@10
    axes[0, 2].plot(df['M'], df['recall_10'], 'o-', label='PQ', linewidth=2, markersize=6)
    axes[0, 2].plot(df['M'], df['hnsw_recall_10'], 's-', label='HNSW+PQ', linewidth=2, markersize=6)
    axes[0, 2].set_xlabel('M (Number of Subquantizers)')
    axes[0, 2].set_ylabel('Recall@10')
    axes[0, 2].set_title('Recall@10')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    axes[0, 2].set_ylim(0, 1)
    
    # 4. å†…å­˜ä½¿ç”¨
    axes[1, 0].plot(df['M'], df['memory_mb'], 'o-', label='PQ', linewidth=2, markersize=6)
    axes[1, 0].plot(df['M'], df['hnsw_memory_mb'], 's-', label='HNSW+PQ', linewidth=2, markersize=6)
    axes[1, 0].set_xlabel('M (Number of Subquantizers)')
    axes[1, 0].set_ylabel('Memory Usage (MB)')
    axes[1, 0].set_title('Memory Usage')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 5. å‹ç¼©æ¯”
    axes[1, 1].plot(df['M'], df['compression_ratio'], 'o-', color='purple', linewidth=2, markersize=6)
    axes[1, 1].set_xlabel('M (Number of Subquantizers)')
    axes[1, 1].set_ylabel('Compression Ratio')
    axes[1, 1].set_title('PQ Compression Ratio')
    axes[1, 1].grid(True, alpha=0.3)
    
    # 6. å­å‘é‡ç»´åº¦ vs å¬å›ç‡
    axes[1, 2].plot(df['sub_dim'], df['recall_10'], 'o-', label='PQ', linewidth=2, markersize=6)
    axes[1, 2].plot(df['sub_dim'], df['hnsw_recall_10'], 's-', label='HNSW+PQ', linewidth=2, markersize=6)
    axes[1, 2].set_xlabel('Subvector Dimension (dim/M)')
    axes[1, 2].set_ylabel('Recall@10')
    axes[1, 2].set_title('Subvector Dimension vs Recall')
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    axes[1, 2].set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig('pq_analysis_chart.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: pq_analysis_chart.png")
    plt.show()

def print_analysis(df):
    """æ‰“å°åˆ†æç»“æœ"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ PQé‡åŒ–å‚æ•°Må½±å“åˆ†ææ€»ç»“")
    print("=" * 60)
    
    print("\nğŸ“Š ä¸»è¦å‘ç°:")
    
    # æœ€ä½³æ€§èƒ½ç‚¹
    best_pq_recall = df.loc[df['recall_10'].idxmax()]
    best_hnsw_recall = df.loc[df['hnsw_recall_10'].idxmax()]
    fastest_pq = df.loc[df['search_time_ms'].idxmin()]
    fastest_hnsw = df.loc[df['hnsw_search_time_ms'].idxmin()]
    
    print(f"ğŸ¯ PQæœ€ä½³å¬å›ç‡: M={best_pq_recall['M']}, å¬å›ç‡={best_pq_recall['recall_10']:.3f}")
    print(f"ğŸ¯ HNSW+PQæœ€ä½³å¬å›ç‡: M={best_hnsw_recall['M']}, å¬å›ç‡={best_hnsw_recall['hnsw_recall_10']:.3f}")
    print(f"âš¡ PQæœ€å¿«æœç´¢: M={fastest_pq['M']}, æ—¶é—´={fastest_pq['search_time_ms']:.2f}ms")
    print(f"âš¡ HNSW+PQæœ€å¿«æœç´¢: M={fastest_hnsw['M']}, æ—¶é—´={fastest_hnsw['hnsw_search_time_ms']:.2f}ms")
    
    print(f"\nğŸ“‹ å…³é”®è¶‹åŠ¿:")
    print(f"â€¢ Må¢åŠ  â†’ å­å‘é‡ç»´åº¦å‡å°‘ â†’ é‡åŒ–ç²¾åº¦å¯èƒ½é™ä½")
    print(f"â€¢ Må¢åŠ  â†’ å­é‡åŒ–å™¨æ•°é‡å¢åŠ  â†’ è®­ç»ƒæ—¶é—´å¢åŠ ")
    print(f"â€¢ Mé€‚ä¸­æ—¶é€šå¸¸æœ‰æœ€ä½³çš„ç²¾åº¦/é€Ÿåº¦å¹³è¡¡")
    
    print(f"\nğŸ“Š è¯¦ç»†ç»“æœ:")
    display_cols = ['M', 'sub_dim', 'recall_10', 'search_time_ms', 'hnsw_recall_10', 'hnsw_search_time_ms']
    print(df[display_cols].to_string(index=False, float_format='%.3f'))
    
    print(f"\nğŸ’¡ æ¨è:")
    # æ‰¾åˆ°å¹³è¡¡ç‚¹ï¼ˆå¬å›ç‡å’Œé€Ÿåº¦çš„ç»¼åˆè¯„åˆ†ï¼‰
    df['pq_score'] = df['recall_10'] * 0.7 - (df['search_time_ms'] / df['search_time_ms'].max()) * 0.3
    df['hnsw_score'] = df['hnsw_recall_10'] * 0.7 - (df['hnsw_search_time_ms'] / df['hnsw_search_time_ms'].max()) * 0.3
    
    best_pq_balanced = df.loc[df['pq_score'].idxmax()]
    best_hnsw_balanced = df.loc[df['hnsw_score'].idxmax()]
    
    print(f"ğŸ“ˆ PQå¹³è¡¡é…ç½®: M={best_pq_balanced['M']} (ç»¼åˆè¯„åˆ†æœ€é«˜)")
    print(f"ğŸ“ˆ HNSW+PQå¹³è¡¡é…ç½®: M={best_hnsw_balanced['M']} (ç»¼åˆè¯„åˆ†æœ€é«˜)")

if __name__ == "__main__":
    df = pq_parameter_demo()
