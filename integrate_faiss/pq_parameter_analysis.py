#!/usr/bin/env python3
"""
PQé‡åŒ–å‚æ•°Må¯¹ç´¢å¼•æ€§èƒ½å½±å“çš„åˆ†æDemo

è¿™ä¸ªè„šæœ¬æµ‹è¯•ä¸åŒçš„Må€¼ï¼ˆPQå­é‡åŒ–å™¨æ•°é‡ï¼‰å¯¹ä»¥ä¸‹æŒ‡æ ‡çš„å½±å“ï¼š
1. ç´¢å¼•æ„å»ºæ—¶é—´
2. å†…å­˜ä½¿ç”¨é‡
3. æœç´¢é€Ÿåº¦
4. å¬å›ç‡ç²¾åº¦

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-09-09
"""

import numpy as np
import faiss
import time
import matplotlib.pyplot as plt
import pandas as pd
from typing import List, Dict, Tuple
import warnings
warnings.filterwarnings('ignore')

class PQBenchmark:
    def __init__(self, dim: int = 128, nb: int = 50000, nq: int = 1000, k: int = 10):
        """
        åˆå§‹åŒ–PQåŸºå‡†æµ‹è¯•
        
        Args:
            dim: å‘é‡ç»´åº¦
            nb: æ•°æ®åº“å‘é‡æ•°é‡
            nq: æŸ¥è¯¢å‘é‡æ•°é‡  
            k: æœç´¢è¿‘é‚»æ•°é‡
        """
        self.dim = dim
        self.nb = nb
        self.nq = nq
        self.k = k
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        print(f"ç”Ÿæˆæµ‹è¯•æ•°æ®: dim={dim}, nb={nb}, nq={nq}")
        np.random.seed(42)
        self.database = np.random.randn(nb, dim).astype(np.float32)
        self.queries = np.random.randn(nq, dim).astype(np.float32)
        
        # è§„èŒƒåŒ–å‘é‡ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
        faiss.normalize_L2(self.database)
        faiss.normalize_L2(self.queries)
        
        # è®¡ç®—çœŸå®çš„æœ€è¿‘é‚»ï¼ˆç”¨äºå¬å›ç‡è®¡ç®—ï¼‰
        print("è®¡ç®—çœŸå®æœ€è¿‘é‚»ï¼ˆç”¨äºå¬å›ç‡è¯„ä¼°ï¼‰...")
        self._compute_ground_truth()
        
    def _compute_ground_truth(self):
        """è®¡ç®—çœŸå®çš„æœ€è¿‘é‚»ä½œä¸ºå¬å›ç‡è¯„ä¼°çš„åŸºå‡†"""
        index_flat = faiss.IndexFlatL2(self.dim)
        index_flat.add(self.database)
        
        _, self.ground_truth = index_flat.search(self.queries, self.k)
        
    def test_pq_parameter(self, m_values: List[int], nbits: int = 6, 
                         hnsw_m: int = 16, ef_construction: int = 200) -> pd.DataFrame:
        """
        æµ‹è¯•ä¸åŒMå€¼å¯¹PQæ€§èƒ½çš„å½±å“
        
        Args:
            m_values: è¦æµ‹è¯•çš„Må€¼åˆ—è¡¨ï¼ˆå­é‡åŒ–å™¨æ•°é‡ï¼‰
            nbits: æ¯ä¸ªPQç çš„ä½æ•°
            hnsw_m: HNSWå›¾çš„è¿æ¥æ•°
            ef_construction: HNSWæ„å»ºæ—¶çš„efå‚æ•°
            
        Returns:
            åŒ…å«æµ‹è¯•ç»“æœçš„DataFrame
        """
        results = []
        
        print(f"\nå¼€å§‹æµ‹è¯•PQå‚æ•°ï¼ŒMå€¼èŒƒå›´: {m_values}")
        print(f"å…¶ä»–å‚æ•°: nbits={nbits}, hnsw_m={hnsw_m}, ef_construction={ef_construction}")
        print("=" * 80)
        
        for m in m_values:
            if self.dim % m != 0:
                print(f"è·³è¿‡ M={m}: ç»´åº¦{self.dim}ä¸èƒ½è¢«Mæ•´é™¤")
                continue
                
            print(f"\næµ‹è¯• M={m} (å­å‘é‡ç»´åº¦: {self.dim//m})")
            print("-" * 40)
            
            try:
                # æµ‹è¯•ç»“æœå­—å…¸
                result = {
                    'M': m,
                    'sub_dim': self.dim // m,
                    'nbits': nbits,
                    'codebook_size': 2**nbits,
                    'compression_ratio': None,
                    'build_time': None,
                    'memory_usage_mb': None,
                    'search_time_us': None,
                    'recall_at_1': None,
                    'recall_at_5': None,
                    'recall_at_10': None
                }
                
                # 1. æµ‹è¯•IndexPQï¼ˆçº¯PQç´¢å¼•ï¼‰
                pq_result = self._test_index_pq(m, nbits)
                result.update(pq_result)
                
                # 2. æµ‹è¯•IndexHNSWPQï¼ˆHNSW+PQç´¢å¼•ï¼‰
                hnswpq_result = self._test_index_hnswpq(m, nbits, hnsw_m, ef_construction)
                
                # å°†HNSWPQç»“æœæ·»åŠ åˆ°resultä¸­ï¼Œå¸¦å‰ç¼€åŒºåˆ†
                for key, value in hnswpq_result.items():
                    result[f'hnsw_{key}'] = value
                
                results.append(result)
                
                # æ‰“å°å½“å‰ç»“æœ
                print(f"PQæ„å»ºæ—¶é—´: {result['build_time']:.2f}s")
                print(f"PQå†…å­˜ä½¿ç”¨: {result['memory_usage_mb']:.1f}MB")
                print(f"PQå¬å›ç‡@10: {result['recall_at_10']:.3f}")
                print(f"HNSWPQæ„å»ºæ—¶é—´: {result['hnsw_build_time']:.2f}s")
                print(f"HNSWPQæœç´¢æ—¶é—´: {result['hnsw_search_time_us']:.1f}Î¼s")
                print(f"HNSWPQå¬å›ç‡@10: {result['hnsw_recall_at_10']:.3f}")
                
            except Exception as e:
                print(f"æµ‹è¯• M={m} æ—¶å‡ºé”™: {e}")
                continue
                
        return pd.DataFrame(results)
    
    def _test_index_pq(self, m: int, nbits: int) -> Dict:
        """æµ‹è¯•çº¯PQç´¢å¼•"""
        # åˆ›å»ºPQç´¢å¼•
        index = faiss.IndexPQ(self.dim, m, nbits, faiss.METRIC_L2)
        
        # è®­ç»ƒç´¢å¼•
        start_time = time.time()
        index.train(self.database)
        build_time = time.time() - start_time
        
        # æ·»åŠ å‘é‡
        index.add(self.database)
        
        # ä¼°ç®—å†…å­˜ä½¿ç”¨
        memory_usage = self.nb * m * nbits / 8 / (1024 * 1024)  # MB
        compression_ratio = (self.nb * self.dim * 4) / (self.nb * m * nbits / 8)
        
        # æœç´¢æµ‹è¯•
        start_time = time.time()
        distances, labels = index.search(self.queries, self.k)
        search_time = (time.time() - start_time) * 1000000 / self.nq  # Î¼s per query
        
        # è®¡ç®—å¬å›ç‡
        recall_1 = self._compute_recall(labels[:, :1], self.ground_truth[:, :1])
        recall_5 = self._compute_recall(labels[:, :5], self.ground_truth[:, :5])
        recall_10 = self._compute_recall(labels[:, :10], self.ground_truth[:, :10])
        
        return {
            'compression_ratio': compression_ratio,
            'build_time': build_time,
            'memory_usage_mb': memory_usage,
            'search_time_us': search_time,
            'recall_at_1': recall_1,
            'recall_at_5': recall_5,
            'recall_at_10': recall_10
        }
    
    def _test_index_hnswpq(self, m: int, nbits: int, hnsw_m: int, ef_construction: int) -> Dict:
        """æµ‹è¯•HNSW+PQç´¢å¼•"""
        # åˆ›å»ºHNSWPQç´¢å¼•
        index = faiss.IndexHNSWPQ(self.dim, m, nbits, hnsw_m, faiss.METRIC_L2)
        index.hnsw.efConstruction = ef_construction
        
        # è®­ç»ƒå’Œæ„å»ºç´¢å¼•
        start_time = time.time()
        index.train(self.database)
        index.add(self.database)
        build_time = time.time() - start_time
        
        # ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆPQç  + HNSWå›¾ï¼‰
        pq_memory = self.nb * m * nbits / 8
        hnsw_memory = self.nb * hnsw_m * 8  # è¿‘ä¼¼ä¼°ç®—
        total_memory = (pq_memory + hnsw_memory) / (1024 * 1024)  # MB
        
        # æœç´¢æµ‹è¯•ï¼ˆä½¿ç”¨ä¸åŒçš„efSearchå€¼ï¼‰
        ef_search_values = [16, 32, 64, 128]
        search_results = {}
        
        for ef_search in ef_search_values:
            index.hnsw.efSearch = ef_search
            
            start_time = time.time()
            distances, labels = index.search(self.queries, self.k)
            search_time = (time.time() - start_time) * 1000000 / self.nq  # Î¼s per query
            
            # è®¡ç®—å¬å›ç‡
            recall_1 = self._compute_recall(labels[:, :1], self.ground_truth[:, :1])
            recall_5 = self._compute_recall(labels[:, :5], self.ground_truth[:, :5])
            recall_10 = self._compute_recall(labels[:, :10], self.ground_truth[:, :10])
            
            search_results[ef_search] = {
                'search_time_us': search_time,
                'recall_at_1': recall_1,
                'recall_at_5': recall_5,
                'recall_at_10': recall_10
            }
        
        # é€‰æ‹©ef_search=64çš„ç»“æœä½œä¸ºä¸»è¦ç»“æœ
        main_result = search_results[64]
        
        return {
            'build_time': build_time,
            'memory_usage_mb': total_memory,
            'search_time_us': main_result['search_time_us'],
            'recall_at_1': main_result['recall_at_1'],
            'recall_at_5': main_result['recall_at_5'],
            'recall_at_10': main_result['recall_at_10'],
            'ef_search_results': search_results
        }
    
    def _compute_recall(self, pred_labels: np.ndarray, true_labels: np.ndarray) -> float:
        """è®¡ç®—å¬å›ç‡"""
        assert pred_labels.shape == true_labels.shape
        
        nq, k = pred_labels.shape
        recall_sum = 0.0
        
        for i in range(nq):
            true_set = set(true_labels[i])
            pred_set = set(pred_labels[i])
            recall_sum += len(true_set.intersection(pred_set)) / len(true_set)
            
        return recall_sum / nq
    
    def plot_results(self, results_df: pd.DataFrame, save_path: str = None):
        """ç»˜åˆ¶æµ‹è¯•ç»“æœå›¾è¡¨"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('PQé‡åŒ–å‚æ•°Må¯¹ç´¢å¼•æ€§èƒ½çš„å½±å“åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ„å»ºæ—¶é—´å¯¹æ¯”
        axes[0, 0].plot(results_df['M'], results_df['build_time'], 'o-', label='PQ', linewidth=2, markersize=8)
        axes[0, 0].plot(results_df['M'], results_df['hnsw_build_time'], 's-', label='HNSW+PQ', linewidth=2, markersize=8)
        axes[0, 0].set_xlabel('M (å­é‡åŒ–å™¨æ•°é‡)')
        axes[0, 0].set_ylabel('æ„å»ºæ—¶é—´ (ç§’)')
        axes[0, 0].set_title('ç´¢å¼•æ„å»ºæ—¶é—´')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å†…å­˜ä½¿ç”¨é‡
        axes[0, 1].plot(results_df['M'], results_df['memory_usage_mb'], 'o-', label='PQ', linewidth=2, markersize=8)
        axes[0, 1].plot(results_df['M'], results_df['hnsw_memory_usage_mb'], 's-', label='HNSW+PQ', linewidth=2, markersize=8)
        axes[0, 1].set_xlabel('M (å­é‡åŒ–å™¨æ•°é‡)')
        axes[0, 1].set_ylabel('å†…å­˜ä½¿ç”¨ (MB)')
        axes[0, 1].set_title('å†…å­˜ä½¿ç”¨é‡')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. å‹ç¼©æ¯”
        axes[0, 2].plot(results_df['M'], results_df['compression_ratio'], 'o-', color='green', linewidth=2, markersize=8)
        axes[0, 2].set_xlabel('M (å­é‡åŒ–å™¨æ•°é‡)')
        axes[0, 2].set_ylabel('å‹ç¼©æ¯”')
        axes[0, 2].set_title('PQå‹ç¼©æ¯”')
        axes[0, 2].grid(True, alpha=0.3)
        
        # 4. æœç´¢æ—¶é—´
        axes[1, 0].plot(results_df['M'], results_df['search_time_us'], 'o-', label='PQ', linewidth=2, markersize=8)
        axes[1, 0].plot(results_df['M'], results_df['hnsw_search_time_us'], 's-', label='HNSW+PQ', linewidth=2, markersize=8)
        axes[1, 0].set_xlabel('M (å­é‡åŒ–å™¨æ•°é‡)')
        axes[1, 0].set_ylabel('æœç´¢æ—¶é—´ (Î¼s/query)')
        axes[1, 0].set_title('å¹³å‡æœç´¢æ—¶é—´')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 5. å¬å›ç‡@10
        axes[1, 1].plot(results_df['M'], results_df['recall_at_10'], 'o-', label='PQ', linewidth=2, markersize=8)
        axes[1, 1].plot(results_df['M'], results_df['hnsw_recall_at_10'], 's-', label='HNSW+PQ', linewidth=2, markersize=8)
        axes[1, 1].set_xlabel('M (å­é‡åŒ–å™¨æ•°é‡)')
        axes[1, 1].set_ylabel('å¬å›ç‡@10')
        axes[1, 1].set_title('å¬å›ç‡@10')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].set_ylim(0, 1)
        
        # 6. å­å‘é‡ç»´åº¦ vs å¬å›ç‡
        axes[1, 2].plot(results_df['sub_dim'], results_df['recall_at_10'], 'o-', label='PQ', linewidth=2, markersize=8)
        axes[1, 2].plot(results_df['sub_dim'], results_df['hnsw_recall_at_10'], 's-', label='HNSW+PQ', linewidth=2, markersize=8)
        axes[1, 2].set_xlabel('å­å‘é‡ç»´åº¦ (dim/M)')
        axes[1, 2].set_ylabel('å¬å›ç‡@10')
        axes[1, 2].set_title('å­å‘é‡ç»´åº¦ vs å¬å›ç‡')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)
        axes[1, 2].set_ylim(0, 1)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def print_analysis_summary(self, results_df: pd.DataFrame):
        """æ‰“å°åˆ†ææ€»ç»“"""
        print("\n" + "="*80)
        print("PQé‡åŒ–å‚æ•°Må½±å“åˆ†ææ€»ç»“")
        print("="*80)
        
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
        print(f"   å‘é‡ç»´åº¦: {self.dim}")
        print(f"   æ•°æ®åº“å¤§å°: {self.nb:,} å‘é‡")
        print(f"   æŸ¥è¯¢æ•°é‡: {self.nq:,}")
        print(f"   æœç´¢è¿‘é‚»æ•°: {self.k}")
        
        print(f"\nğŸ“ˆ ä¸»è¦å‘ç°:")
        
        # æœ€ä½³æ€§èƒ½ç‚¹åˆ†æ
        best_recall_pq = results_df.loc[results_df['recall_at_10'].idxmax()]
        best_recall_hnsw = results_df.loc[results_df['hnsw_recall_at_10'].idxmax()]
        fastest_search_pq = results_df.loc[results_df['search_time_us'].idxmin()]
        fastest_search_hnsw = results_df.loc[results_df['hnsw_search_time_us'].idxmin()]
        
        print(f"   ğŸ¯ PQæœ€ä½³å¬å›ç‡: M={best_recall_pq['M']}, å¬å›ç‡={best_recall_pq['recall_at_10']:.3f}")
        print(f"   ğŸ¯ HNSW+PQæœ€ä½³å¬å›ç‡: M={best_recall_hnsw['M']}, å¬å›ç‡={best_recall_hnsw['hnsw_recall_at_10']:.3f}")
        print(f"   âš¡ PQæœ€å¿«æœç´¢: M={fastest_search_pq['M']}, æ—¶é—´={fastest_search_pq['search_time_us']:.1f}Î¼s")
        print(f"   âš¡ HNSW+PQæœ€å¿«æœç´¢: M={fastest_search_hnsw['M']}, æ—¶é—´={fastest_search_hnsw['hnsw_search_time_us']:.1f}Î¼s")
        
        # Må€¼è¶‹åŠ¿åˆ†æ
        print(f"\nğŸ“‹ Må€¼å½±å“è¶‹åŠ¿:")
        print(f"   â€¢ Må€¼å¢åŠ  â†’ å­å‘é‡ç»´åº¦å‡å°‘ â†’ é‡åŒ–ç²¾åº¦é™ä½")
        print(f"   â€¢ Må€¼å¢åŠ  â†’ ç ä¹¦æ•°é‡å¢åŠ  â†’ è®­ç»ƒæ—¶é—´å¢åŠ ")
        print(f"   â€¢ Må€¼å¢åŠ  â†’ å­˜å‚¨å¼€é”€åŸºæœ¬ä¸å˜ï¼ˆM*nbitså›ºå®šï¼‰")
        
        # æ¨èé…ç½®
        print(f"\nğŸ’¡ æ¨èé…ç½®:")
        balanced_idx = results_df.iloc[(results_df['recall_at_10'] * 0.7 + (1 - results_df['search_time_us'] / results_df['search_time_us'].max()) * 0.3).idxmax()]
        balanced_hnsw_idx = results_df.iloc[(results_df['hnsw_recall_at_10'] * 0.7 + (1 - results_df['hnsw_search_time_us'] / results_df['hnsw_search_time_us'].max()) * 0.3).idxmax()]
        
        print(f"   ğŸ“ˆ PQå‡è¡¡é…ç½®: M={balanced_idx['M']} (å¬å›ç‡={balanced_idx['recall_at_10']:.3f}, æœç´¢æ—¶é—´={balanced_idx['search_time_us']:.1f}Î¼s)")
        print(f"   ğŸ“ˆ HNSW+PQå‡è¡¡é…ç½®: M={balanced_hnsw_idx['M']} (å¬å›ç‡={balanced_hnsw_idx['hnsw_recall_at_10']:.3f}, æœç´¢æ—¶é—´={balanced_hnsw_idx['hnsw_search_time_us']:.1f}Î¼s)")
        
        print(f"\nè¯¦ç»†ç»“æœè¡¨æ ¼:")
        print(results_df[['M', 'sub_dim', 'recall_at_10', 'search_time_us', 'hnsw_recall_at_10', 'hnsw_search_time_us']].to_string(index=False))

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ PQé‡åŒ–å‚æ•°Må½±å“åˆ†æDemo")
    print("=" * 80)
    
    # åˆå§‹åŒ–åŸºå‡†æµ‹è¯•
    benchmark = PQBenchmark(
        dim=128,        # 128ç»´å‘é‡
        nb=50000,       # 5ä¸‡ä¸ªæ•°æ®åº“å‘é‡
        nq=1000,        # 1000ä¸ªæŸ¥è¯¢å‘é‡
        k=10            # æœç´¢å‰10ä¸ªé‚»å±…
    )
    
    # æµ‹è¯•ä¸åŒçš„Må€¼
    # Må€¼å¿…é¡»èƒ½æ•´é™¤ç»´åº¦ï¼Œå¯¹äº128ç»´ï¼Œå¯é€‰æ‹©: 1, 2, 4, 8, 16, 32, 64, 128
    m_values = [1, 2, 4, 8, 16, 32, 64]
    
    print(f"\nğŸ”¬ å¼€å§‹æµ‹è¯•Må€¼: {m_values}")
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    results_df = benchmark.test_pq_parameter(
        m_values=m_values,
        nbits=6,            # 6ä½é‡åŒ– (64ä¸ªèšç±»ä¸­å¿ƒ)
        hnsw_m=16,          # HNSWè¿æ¥æ•°
        ef_construction=200  # HNSWæ„å»ºå‚æ•°
    )
    
    # ä¿å­˜ç»“æœ
    results_df.to_csv('pq_benchmark_results.csv', index=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: pq_benchmark_results.csv")
    
    # ç»˜åˆ¶å›¾è¡¨
    benchmark.plot_results(results_df, 'pq_benchmark_analysis.png')
    
    # æ‰“å°åˆ†ææ€»ç»“
    benchmark.print_analysis_summary(results_df)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
